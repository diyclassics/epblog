{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Gemination (Wills 1996)\"\n",
    "description: \"Code notebook providing basic formalization for 'gemination' as defined in Wills 1996\"\n",
    "author: \"Patrick J. Burns\"\n",
    "date: \"2023-06-28\"\n",
    "categories: [replicating-classics, latin, data-science, allusion]\n",
    "bibliography: \"references.bib\"\n",
    "nocite: |\n",
    "  @wills_repetition_1996\n",
    "# image: \"image.jpg\"\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of his [1996 monograph](https://global.oup.com/academic/product/repetition-in-latin-poetry-9780198140849?cc=us&lang=en&) on repetition in Latin poetry, Jeffrey Wills [-@wills_repetition_1996] discusses gemination. i.e. \"the repetition of a word in the same form in the same clause with no additional expansion.\" In this notebook, we will formalize Wills' definition of gemination into code using LatinCy.\n",
    "\n",
    "Let's start by setting up a code notebook with Python imports, etc. We will use [CLTK Readers](https://github.com/diyclassics/cltk_readers) with the [CLTK-Tesserae](https://github.com/cltk/lat_text_tesserae) texts as our exploratory background for gemination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from collections import Counter\n",
    "from natsort import natsorted\n",
    "\n",
    "import spacy\n",
    "from cltkreaders.lat import LatinTesseraeCorpusReader\n",
    "\n",
    "from latintools import preprocess\n",
    "\n",
    "from tabulate import tabulate\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wills uses the following line from Virgil's *Eclogues* to illustrate gemination (V. *Ecl.* 2.69):\n",
    "\n",
    "> Corydon, Corydon, quae te dementia cepit!\n",
    "\n",
    "Let's begin there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vergil.eclogues.tess\n"
     ]
    }
   ],
   "source": [
    "# Set up corpus\n",
    "\n",
    "T = LatinTesseraeCorpusReader()\n",
    "\n",
    "# Get Eclogues file\n",
    "\n",
    "eclogues = [file for file in T.fileids() if 'eclogues' in file][0]\n",
    "print(eclogues)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load a LatinCy model to assist with matching Latin wordforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up NLP\n",
    "\n",
    "nlp = spacy.load('la_core_web_lg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple gemination"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering Wills' basic definition from above, we can use the following pseudocode as a starting point...\n",
    "\n",
    "- Get a line of Virgil  \n",
    "- Create a LatinCy Doc for each line  \n",
    "- Count the `norm` token attributes for each line  \n",
    "- Check `norm` count, i.e. if the count of `norm` token attributes is greater than 1, then the line has gemination  \n",
    "\n",
    "Note that Wills specifically defines the scope of gemination as a clause (not a line); we will return to this point in a future notebook where we introduce some clause parsing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get a line of Virgil**  \n",
    "For the Tesserae texts, CLTK Readers has a data structure called `doc_rows` that, at least for poetry, gives us a dictionary with the format {*citation*: *line*, etc.}. Let's get the docrows for the *Eclogues* and print a sample line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all Eclogue rows\n",
    "\n",
    "docrows = next(T.doc_rows(eclogues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, Corydon, Corydon, quae te dementia cepit!\n"
     ]
    }
   ],
   "source": [
    "# Get a row\n",
    "\n",
    "test = docrows['<verg. ecl. 2.69>']\n",
    "print(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see our gemination—specifically the example Wills uses in his defintion—with the repetition of *Corydon*.\n",
    "\n",
    "**Create a LatinCy Doc**  \n",
    "Next we can create a spaCy Doc for each line. The Doc contains all sorts of annotations useful for philological work. We will use the `norm` token attribute here to help us match wordforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "# Create LatinCy Doc for line\n",
    "\n",
    "doc = nlp(test)\n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Index  Token     Norm\n",
      "-------  --------  --------\n",
      "      0  Ah        ah\n",
      "      1  ,         ,\n",
      "      2  Corydon   corydon\n",
      "      3  ,         ,\n",
      "      4  Corydon   corydon\n",
      "      5  ,         ,\n",
      "      6  quae      quae\n",
      "      7  te        te\n",
      "      8  dementia  dementia\n",
      "      9  cepit     cepit\n",
      "     10  !         !\n"
     ]
    }
   ],
   "source": [
    "# Print norm examples\n",
    "print(tabulate([[token.i, token.text, token.norm_] for token in doc], headers=['Index','Token', 'Norm']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking ahead, if we use lines as is from the Tesserae texts, we have to deal with punctuation. Wills is concerned with the repetition of *Corydon*, not the repetition of the commas! One way we can deal with this is to preprocess the lines to remove punctuation before creating the Docs. We will discuss the philological implications of preprocessing in a future notebook. For now, we are going to import a script called `preprocess` that removes punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Index  Token     Norm\n",
      "-------  --------  --------\n",
      "      0  Ah        ah\n",
      "      1  Corydon   corydon\n",
      "      2  Corydon   corydon\n",
      "      3  quae      quae\n",
      "      4  te        te\n",
      "      5  dementia  dementia\n",
      "      6  cepit     cepit\n"
     ]
    }
   ],
   "source": [
    "# Create LatinCy Doc for preprocessed line and print example\n",
    "\n",
    "doc = nlp(preprocess(test, lower=False))\n",
    "print(tabulate([[token.i, token.text, token.norm_] for token in doc], headers=['Index','Token', 'Norm']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the `norm` token attributes**  \n",
    "We can now count the `norm` token attributes for each line using a `Counter` from the `collections` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'corydon': 2, 'ah': 1, 'quae': 1, 'te': 1, 'dementia': 1, 'cepit': 1})\n"
     ]
    }
   ],
   "source": [
    "# Count `norm` attr in Doc tokens\n",
    "\n",
    "norms = [token.norm_ for token in doc]\n",
    "norms_counter = Counter(norms)\n",
    "print(norms_counter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check `norm` count**\n",
    "\n",
    "We can now check the `norm` count for each line. If the count is greater than 1, then the line has gemination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of geminations: 1\n",
      "['corydon']\n"
     ]
    }
   ],
   "source": [
    "geminations = [k for k, v in norms_counter.items() if v > 1]\n",
    "print(f'Number of geminations: {len(geminations)}')\n",
    "print(f'{geminations}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We knew from Wills that this line would have gemination; of course, not all lines do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semiputata tibi frondosa uitis in ulmo est\n",
      "Number of geminations: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Try a different line\n",
    "\n",
    "test = docrows['<verg. ecl. 2.70>']\n",
    "doc = nlp(preprocess(test))\n",
    "norms = [token.norm_ for token in doc]\n",
    "norms_counter = Counter(norms)\n",
    "geminations = [k for k, v in norms_counter.items() if v > 1]\n",
    "\n",
    "print(doc.text)\n",
    "print(f'Number of geminations: {len(geminations)}')\n",
    "print(f'{geminations}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having worked through our pseudocode, we can now put it all together into a function that we can use to check for gemination in any line of Latin poetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geminations(Doc):\n",
    "    norms = [token.norm_ for token in Doc]\n",
    "    norms_counter = Counter(norms)\n",
    "    geminations = [k for k, v in norms_counter.items() if v > 1]\n",
    "    return geminations    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, we can loop through the docrows for the *Eclogues* and check for gemination in each line. In the example below, we `break` after the first match as we are only checking at this point that the function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<verg. ecl. 1.23>: ['sic']\n",
      "sic canibus catulos similis, sic matribus haedos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in docrows.items():\n",
    "    doc = nlp(preprocess(v, lower=False))\n",
    "    geminations = get_geminations(doc)\n",
    "    if len(geminations) > 0:\n",
    "        print(f'{k}: {geminations}')\n",
    "        print(f'{v}')\n",
    "        print('\\n')\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More useful of course would be to collect all of the geminations into a data structure like a dictionary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 828/828 [00:03<00:00, 207.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 105 geminations in Virgil's *Eclogues*.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "virgil_geminations = {}\n",
    "\n",
    "for k, v in tqdm(docrows.items()):\n",
    "    doc = nlp(preprocess(v))\n",
    "    geminations = get_geminations(doc)\n",
    "    if geminations:\n",
    "        virgil_geminations[k] = (v, geminations)\n",
    "\n",
    "print(f'There are {len(virgil_geminations)} geminations in Virgil\\'s *Eclogues*.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the first five examples from our search:\n",
      "\n",
      "<verg. ecl. 1.23>: sic canibus catulos similis, sic matribus haedos\n",
      "<verg. ecl. 1.33>: nec spes libertatis erat, nec cura peculi:\n",
      "<verg. ecl. 1.63>: aut Ararim Parthus bibet, aut Germania Tigrim,\n",
      "<verg. ecl. 1.75>: Ite meae, felix quondam pecus, ite capellae.\n",
      "<verg. ecl. 2.20>: quam dives pecoris, nivei quam lactis abundans.\n"
     ]
    }
   ],
   "source": [
    "print('Here are the first five examples from our search:\\n')\n",
    "for k, v in list(virgil_geminations.items())[:5]:\n",
    "    print(f'{k}: {v[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note V. *Ecl.* 1.75 as an example of why we use `norm` instead of `text` for matching wordforms. *Ite* is capitalized here only because it is the first word in the sentence, but should be matched against *ite* regardless of case. Note the following in Python string matching..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('Ite' == 'ite')\n",
    "print('ite' == 'ite')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make it easier to see gemination in our texts by formatting matched tokens in HTML. We can use the `display` module from the `IPython` package to display the HTML in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gemination(gemination):\n",
    "    html = ''\n",
    "    line = nlp(gemination[0])\n",
    "    terms = gemination[1]\n",
    "\n",
    "    for token in line:\n",
    "        if token.norm_ in terms:\n",
    "            token = f'<span style=\"color: green;\">{token}</span>'\n",
    "        html += f'{token} '\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the first five examples from our search:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; font-weight: bold;\">verg. ecl. 1.23</span><br><span style=\"color: green;\">sic</span> canibus catulos similis , <span style=\"color: green;\">sic</span> matribus haedos <br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; font-weight: bold;\">verg. ecl. 1.33</span><br><span style=\"color: green;\">nec</span> spes libertatis erat , <span style=\"color: green;\">nec</span> cura peculi : <br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; font-weight: bold;\">verg. ecl. 1.63</span><br><span style=\"color: green;\">aut</span> Ararim Parthus bibet , <span style=\"color: green;\">aut</span> Germania Tigrim , <br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; font-weight: bold;\">verg. ecl. 1.75</span><br><span style=\"color: green;\">Ite</span> meae , felix quondam pecus , <span style=\"color: green;\">ite</span> capellae . <br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; font-weight: bold;\">verg. ecl. 2.20</span><br><span style=\"color: green;\">quam</span> dives pecoris , nivei <span style=\"color: green;\">quam</span> lactis abundans . <br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Here are the first five examples from our search:')\n",
    "for k, v in list(virgil_geminations.items())[:5]:\n",
    "    # Note that if you do not remove the angle brackets from the Tesserae citation, it will be ignored as a (bad) HTML tag in the formatting below.\n",
    "    citation = k.replace('<', '').replace('>', '') \n",
    "    citation = f'<span style=\"color: black; font-weight: bold;\">{citation}</span>'\n",
    "    text = display_gemination(v)\n",
    "    html = '<br>'.join([citation, text])\n",
    "    html += '<br><br>'\n",
    "    display(HTML(html))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Moreover, we can write these matches to a file, formatting the geminations to make them easier to spot, here wrapping repeitions with asterisks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_gemination(gemination):\n",
    "    txt = ''\n",
    "    line = nlp(gemination[0])\n",
    "    terms = gemination[1]\n",
    "\n",
    "    for token in line:\n",
    "        if token.norm_ in terms:\n",
    "            token = f'*{token}*'\n",
    "        txt += f'{token} '\n",
    "    return txt\n",
    "\n",
    "with open('eclogue_geminations.txt', 'w') as f:\n",
    "    for k, v in virgil_geminations.items():\n",
    "        citation = k.replace('<', '').replace('>', '')\n",
    "        citation = f'{citation}'\n",
    "        text = format_gemination(v)\n",
    "        f.write(f'{citation}\\t{text}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a line like *Ecl.* 4.51 appears in the output...\n",
    "\n",
    "> terrasque tractusque maris caelumque profundum ! \n",
    "\n",
    "...as *que* is considered a token in the LatinCy model.\n",
    "\n",
    "Accordingly, we may want to have a way to drop certain tokens from our matching process. We add below an `exclude` parameter to the `get_geminations` function to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before...\n",
      "['que']\n",
      "\n",
      "After...\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def get_geminations(Doc, exclude=[]):\n",
    "    norms = [token.norm_ for token in Doc]\n",
    "    norms_counter = Counter(norms)\n",
    "    geminations = [k for k, v in norms_counter.items() if v > 1 and k not in exclude]\n",
    "    return geminations    \n",
    "\n",
    "exclude =['que']\n",
    "\n",
    "test = nlp(preprocess(docrows['<verg. ecl. 4.51>'], lower=False))\n",
    "\n",
    "print('Before...')\n",
    "print(get_geminations(test))\n",
    "print()\n",
    "print('After...')\n",
    "print(get_geminations(test, exclude=exclude))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write to file again, this time excluding *que*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 828/828 [00:03<00:00, 213.19it/s]\n"
     ]
    }
   ],
   "source": [
    "virgil_geminations = {}\n",
    "\n",
    "for k, v in tqdm(docrows.items()):\n",
    "    doc = nlp(preprocess(v))\n",
    "    geminations = get_geminations(doc, exclude=['que'])\n",
    "    if geminations:\n",
    "        virgil_geminations[k] = (v, geminations)\n",
    "\n",
    "with open('eclogue_geminations.txt', 'w') as f:\n",
    "    for k, v in virgil_geminations.items():\n",
    "        citation = k.replace('<', '').replace('>', '')\n",
    "        citation = f'{citation}'\n",
    "        text = format_gemination(v)\n",
    "        f.write(f'{citation}\\t{text}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have worked only with the *Eclogues*. We could easily expand this gemination search to other texts in the Tesserae corpus. Here is an example of expanding it to all epic poems in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 120 epic poems in the Tesserae collection.\n"
     ]
    }
   ],
   "source": [
    "# Geminations in all Latin epic\n",
    "\n",
    "# Note here I get the year from the Tesserae metadata, sort the files chronologically, and then discard the date information\n",
    "epic = natsorted([(file, int(T.metadata('date', file))) for file in T.fileids() if T.metadata('genre', file) == 'epic'], key=lambda x: x[1])\n",
    "epic = [file for file, _ in epic]\n",
    "print(f'There are {len(epic)} epic poems in the Tesserae collection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [06:49<00:00,  3.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# This takes about 7 minutes on my laptop\n",
    "\n",
    "all_geminations = {}\n",
    "\n",
    "for file in tqdm(epic):\n",
    "    docrows = next(T.doc_rows(file))\n",
    "    for k, v in docrows.items():\n",
    "        doc = nlp(preprocess(v))\n",
    "        geminations = get_geminations(doc, exclude=['que'])\n",
    "        if geminations:\n",
    "            all_geminations[k] = (v, geminations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "with open('epic_geminations.tsv', 'w') as f:\n",
    "    f.write('citation\\ttext\\n')\n",
    "    for k, v in all_geminations.items():\n",
    "        citation = k.replace('<', '').replace('>', '')\n",
    "        citation = f'{citation}'\n",
    "        text = format_gemination(v)\n",
    "        f.write(f'{citation}\\t{text}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has been an introduction to formalizing a literary critical/philological argument using LatinCy, an example that barely takes us past the first page of Wills Part I. In subsequent notebooks, we will explore variations on gemination and other types of repetition."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "::: {#refs}\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit ('exploratory-blog')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cfcea2cd4d375f5df29dea34308e490dbf87598afedd7a9dce8ea7841d1a117"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
